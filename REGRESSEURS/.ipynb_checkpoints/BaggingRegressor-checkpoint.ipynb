{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2552f3af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation croisée - MAE (Mean Absolute Error) :\n",
      "Scores de validation croisée (MAE) : [0.37637073 0.37145021 0.37967323 0.37211201 0.37441318]\n",
      "Moyenne des scores : 0.37\n",
      "Écart type des scores : 0.00\n",
      "\n",
      "Évaluation sur l'ensemble de test :\n",
      "MAE (Mean Absolute Error) : 0.34\n",
      "MSE (Mean Squared Error) : 0.24\n",
      "RMSE (Root Mean Squared Error) : 0.49\n",
      "R² (Coefficient de détermination) : 0.56\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Charger les données\n",
    "data = pd.read_csv('listings.csv')\n",
    "\n",
    "# Traitement des données manquantes sans utiliser inplace=True\n",
    "data['last_review'] = data['last_review'].fillna(data['last_review'].mode()[0])\n",
    "data['reviews_per_month'] = data['reviews_per_month'].fillna(data['reviews_per_month'].median())\n",
    "\n",
    "# Sélection des variables sans inclure la colonne 'neighbourhood_group'\n",
    "features = ['latitude', 'longitude', 'room_type', 'minimum_nights', 'number_of_reviews', 'last_review', 'reviews_per_month', 'calculated_host_listings_count', 'availability_365']\n",
    "target = 'price'\n",
    "\n",
    "X = data[features]\n",
    "y = np.log1p(data[target])  # Transformation log du prix\n",
    "\n",
    "# Diviser les données en train et test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Prétraitement des données\n",
    "numeric_features = ['latitude', 'longitude', 'minimum_nights', 'number_of_reviews', 'reviews_per_month', 'calculated_host_listings_count', 'availability_365']\n",
    "categorical_features = ['room_type', 'last_review']\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "# Modèle Bagging avec DecisionTreeRegressor\n",
    "bagging_regressor = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', BaggingRegressor(n_estimators=100, random_state=42))\n",
    "])\n",
    "\n",
    "# Validation croisée (score MAE)\n",
    "cross_val_scores = cross_val_score(bagging_regressor, X_train, y_train, cv=5, scoring='neg_mean_absolute_error')\n",
    "\n",
    "# Affichage des résultats de validation croisée\n",
    "print(\"Validation croisée - MAE (Mean Absolute Error) :\")\n",
    "print(\"Scores de validation croisée (MAE) :\", -cross_val_scores)  # On prend l'inverse du score car il est retourné négatif\n",
    "print(\"Moyenne des scores : {:.2f}\".format(-cross_val_scores.mean()))\n",
    "print(\"Écart type des scores : {:.2f}\".format(cross_val_scores.std()))\n",
    "\n",
    "# Entraînement du modèle sur l'ensemble des données d'entraînement\n",
    "bagging_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Prédiction sur l'ensemble de test\n",
    "y_pred = bagging_regressor.predict(X_test)\n",
    "\n",
    "# Affichage des métriques d'évaluation\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)  # Calcul du RMSE manuellement\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"\\nÉvaluation sur l'ensemble de test :\")\n",
    "print(f\"MAE (Mean Absolute Error) : {mae:.2f}\")\n",
    "print(f\"MSE (Mean Squared Error) : {mse:.2f}\")\n",
    "print(f\"RMSE (Root Mean Squared Error) : {rmse:.2f}\")\n",
    "print(f\"R² (Coefficient de détermination) : {r2:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45b0b01",
   "metadata": {},
   "source": [
    "Le modèle de régression utilisé repose sur une méthode d’agrégation par Bagging avec un estimateur de base de type DecisionTreeRegressor.\n",
    "Il a été évalué à l’aide d’une validation croisée sur l’ensemble d’apprentissage et d’une évaluation finale sur un jeu de test indépendant.\n",
    "\n",
    "\n",
    " Validation croisée (5 folds)\n",
    "MAE moyen : 0.37\n",
    "\n",
    "Écart-type : 0.00\n",
    "\n",
    "Cela indique que les erreurs de prédiction sont très stables sur les différentes sous-parties de l’ensemble d’entraînement\n",
    "ce qui reflète une bonne robustesse du modèle.\n",
    "\n",
    " Évaluation sur le jeu de test\n",
    "MAE : 0.34\n",
    "\n",
    "MSE : 0.24\n",
    "\n",
    "RMSE : 0.49\n",
    "\n",
    "R² : 0.56\n",
    "\n",
    "Le modèle atteint une précision légèrement meilleure sur le jeu de test que pendant la validation croisée. \n",
    "Il explique 56 % de la variance du logarithme du prix (log1p(price)), \n",
    "ce qui est acceptable dans un contexte de données réelles comportant du bruit et des facteurs non observés (qualité du logement, saisonnalité, avis clients, etc.).\n",
    "\n",
    "\n",
    "\n",
    " Interprétation\n",
    " \n",
    " \n",
    "Le MAE de 0.34 sur le logarithme du prix correspond à une erreur absolue moyenne d’environ 40 % en échelle réelle (selon la formule exp(MAE) - 1 ≈ 0.4)\n",
    "ce qui reste raisonnable dans un contexte immobilier à forte variabilité.\n",
    "\n",
    "Le R² de 0.56 suggère qu’il reste encore 44 % de variance non expliquée, ce qui peut venir :\n",
    "\n",
    "de variables non incluses dans le modèle,\n",
    "\n",
    "d une non-linéarité complexe entre les variables ou de bruit intrinsèque dans les données.\n",
    "\n",
    "\n",
    "\n",
    "Limites identifiées\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Utilisation du log(price) :\n",
    "\n",
    "Si cela stabilise les extrêmes, cela rend les erreurs moins lisibles pour une interprétation métier. Il faudrait retransformer (np.expm1) les prédictions pour les comparer en euros.\n",
    "\n",
    "Variables non exploitables :\n",
    "\n",
    "La variable last_review est actuellement traitée comme catégorielle via OneHot, ce qui n’a pas vraiment de sens temporellement. Elle pourrait être remplacée par :\n",
    "\n",
    "un nombre de jours depuis la dernière review,\n",
    "\n",
    "ou convertie en année/mois.\n",
    "\n",
    "Peu d interactions entre les variables :\n",
    "\n",
    "Le modèle de régression par arbres individuels ne capture pas toujours efficacement les interactions complexes entre variables.\n",
    "\n",
    "Pas de sélection de caractéristiques :\n",
    "\n",
    "Toutes les variables disponibles ont été utilisées sans évaluation de leur pertinence réelle.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " Axes d amélioration\n",
    " \n",
    " \n",
    " \n",
    "Remodeler la variable last_review :\n",
    "\n",
    "La transformer en durée depuis la dernière review (en jours), ce qui est une information temporelle plus utile que son label brut.\n",
    "\n",
    "Tester d autres modèles plus puissants :\n",
    "\n",
    "RandomForestRegressor, GradientBoostingRegressor ou XGBoost peuvent offrir de meilleures performances.\n",
    "\n",
    "Comparer les performances avec et sans Bagging.\n",
    "\n",
    "Ajouter des variables dérivées :\n",
    "\n",
    "Exemple : log(minimum_nights), reviews_per_month * number_of_reviews, ou des ratios personnalisés.\n",
    "\n",
    "Utiliser la sélection de caractéristiques :\n",
    "\n",
    "Par exemple, avec SelectKBest, RFE, ou des méthodes intégrées au modèle.\n",
    "\n",
    "Évaluer les performances avec price (valeurs réelles) :\n",
    "\n",
    "Retransformer les prédictions avec np.expm1(y_pred) pour évaluer en unités monétaires et non en log.\n",
    "\n",
    "\n",
    "Conclusion\n",
    "Le modèle bagging a permis d’obtenir une prédiction robuste et généralisable avec une bonne stabilité (écart-type faible);\n",
    "des résultats raisonnables (MAE de 0.34 et R² de 0.56). \n",
    "Toutefois, des marges d amélioration existent sur le choix des variables, leur traitement, et le type de modèle. \n",
    "Cela ouvre la voie à une optimisation plus poussée dans les prochaines itérations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ML 2025)",
   "language": "python",
   "name": "ml-project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
