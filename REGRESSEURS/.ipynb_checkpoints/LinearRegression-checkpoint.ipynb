{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a1f87d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßæ Colonnes du dataset : ['id', 'name', 'host_id', 'host_name', 'neighbourhood_group', 'neighbourhood', 'latitude', 'longitude', 'room_type', 'price', 'minimum_nights', 'number_of_reviews', 'last_review', 'reviews_per_month', 'calculated_host_listings_count', 'availability_365']\n",
      "      id                                               name  host_id  \\\n",
      "0   2384  Hyde Park - Walk to UChicago, 10 min to McCormick     2613   \n",
      "1   4505  394 Great Reviews. 127 y/o House. 40 yds to tr...     5775   \n",
      "2   7126                Tiny Studio Apartment 94 Walk Score    17928   \n",
      "3   9811                      Barbara's Hideaway - Old Town    33004   \n",
      "4  10610                   3 Comforts of Cooperative Living     2140   \n",
      "\n",
      "          host_name  neighbourhood_group   neighbourhood  latitude  longitude  \\\n",
      "0           Rebecca                  NaN       Hyde Park  41.78790  -87.58780   \n",
      "1  Craig & Kathleen                  NaN  South Lawndale  41.85495  -87.69696   \n",
      "2             Sarah                  NaN       West Town  41.90289  -87.68182   \n",
      "3       At Home Inn                  NaN    Lincoln Park  41.91769  -87.63788   \n",
      "4              Lois                  NaN       Hyde Park  41.79612  -87.59261   \n",
      "\n",
      "         room_type  price  minimum_nights  number_of_reviews last_review  \\\n",
      "0     Private room     60               2                178  2019-12-15   \n",
      "1  Entire home/apt    105               2                395  2020-07-14   \n",
      "2  Entire home/apt     60               2                384  2020-03-08   \n",
      "3  Entire home/apt     65               4                 49  2019-10-23   \n",
      "4     Private room     21               1                 44  2020-02-14   \n",
      "\n",
      "   reviews_per_month  calculated_host_listings_count  availability_365  \n",
      "0               2.56                               1               353  \n",
      "1               2.81                               1               155  \n",
      "2               2.81                               1               321  \n",
      "3               0.63                               9               300  \n",
      "4               0.61                               5               168  \n"
     ]
    }
   ],
   "source": [
    "# =====================\n",
    "# 1. IMPORTS ESSENTIELS\n",
    "# =====================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, f_regression, RFE\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import random\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# =====================\n",
    "# 2. CHARGEMENT DES DONN√âES\n",
    "# =====================\n",
    "data = pd.read_csv('listings.csv')\n",
    "\n",
    "print(\"üßæ Colonnes du dataset :\", data.columns.tolist())\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f5cbc2-bd85-40df-ae28-0e9cc633c9c3",
   "metadata": {},
   "source": [
    "Cela permet d‚Äôexplorer la structure du jeu de donn√©es, d‚Äôidentifier les variables disponibles (num√©riques, cat√©gorielles, prix, localisation‚Ä¶) et de pr√©parer les √©tapes suivantes : nettoyage, s√©lection des features et mod√©lisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40935a9a-c1fd-448b-ad87-5a526ff3417e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =====================\n",
    "# 3. D√âFINITION DES VARIABLES\n",
    "# =====================\n",
    "\n",
    "# Variables num√©riques et cat√©gorielles utilis√©es pour la pr√©diction\n",
    "numeric_features = ['latitude', 'longitude', 'minimum_nights', 'number_of_reviews', 'reviews_per_month']\n",
    "categorical_features = ['neighbourhood', 'room_type']\n",
    "\n",
    "# =====================\n",
    "# 4. PIPELINES DE PR√âTRAITEMENT\n",
    "# =====================\n",
    "\n",
    "# Transformer num√©rique avec imputation et normalisation robuste\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),  # Imputer les valeurs manquantes\n",
    "    ('scaler', RobustScaler())  # Utiliser RobustScaler pour limiter l'impact des outliers\n",
    "])\n",
    "\n",
    "# Transformer cat√©gorielle avec imputation et encodage one-hot\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),  # Imputer les valeurs manquantes\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))  # Encoder les variables cat√©gorielles\n",
    "])\n",
    "\n",
    "# Combinaison des transformations\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numeric_transformer, numeric_features),\n",
    "    ('cat', categorical_transformer, categorical_features)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6519521-5d3d-4cf3-8516-8a1d08fdd1e7",
   "metadata": {},
   "source": [
    "S√©lection des variables pertinentes\n",
    "Dans cette √©tape, on s√©lectionne les variables jug√©es utiles pour pr√©dire la variable cible (probablement le prix d‚Äôune location Airbnb). Ces variables sont s√©par√©es en deux types :\n",
    "Variables num√©riques : latitude, longitude, minimum_nights, number_of_reviews, reviews_per_month. Ces variables ont des valeurs continues, souvent sujettes √† des valeurs manquantes ou aberrantes.\n",
    "Variables cat√©gorielles : neighbourhood, room_type, qui sont des libell√©s ou cat√©gories non num√©riques mais tr√®s informatives sur le logement.\n",
    "\n",
    "Construction des pipelines de pr√©traitement\n",
    "Pour pr√©parer les donn√©es, on utilise deux pipelines parall√®les selon le type de variable :\n",
    "Pipeline num√©rique :\n",
    "Imputation : remplacement des valeurs manquantes par la moyenne (SimpleImputer(strategy='mean')).\n",
    "Normalisation robuste : on applique un RobustScaler, qui est moins sensible aux valeurs extr√™mes que le StandardScaler. Cela permet de centrer et r√©duire les donn√©es tout en limitant l‚Äôinfluence des outliers.\n",
    "\n",
    "Pipeline cat√©goriel :\n",
    "Imputation : les cat√©gories manquantes sont remplac√©es par la modalit√© la plus fr√©quente (most_frequent).\n",
    "Encodage one-hot : chaque cat√©gorie devient une colonne binaire (0 ou 1), ce qui permet de rendre les variables cat√©gorielles exploitables par les mod√®les lin√©aires et autres algorithmes.\n",
    "\n",
    "Fusion des deux pipelines\n",
    "Avec ColumnTransformer, on applique chaque pipeline aux colonnes concern√©es (num√©riques ou cat√©gorielles) et on les combine. Ce bloc constitue le pr√©traitement automatique des donn√©es, qui sera int√©gr√© dans un pipeline global avec le mod√®le de r√©gression plus tard.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a8fa22-ac03-45d3-8800-431ee88a12e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =====================\n",
    "# 5. PIPELINE COMPLET AVEC MOD√àLE\n",
    "# =====================\n",
    "\n",
    "# Ajouter la s√©lection des caract√©ristiques avec RFE\n",
    "regressor = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('feature_selection', RFE(LinearRegression(), n_features_to_select=5)),  # S√©lection des meilleures caract√©ristiques\n",
    "    ('regressor', LinearRegression())  # R√©gression lin√©aire\n",
    "])\n",
    "\n",
    "# =====================\n",
    "# 6. S√âPARATION DES DONN√âES\n",
    "# =====================\n",
    "X = data[numeric_features + categorical_features]\n",
    "y = np.log1p(data['price'])  # On pr√©dit log(1 + prix) pour stabiliser la variance\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275d52ff-e8f9-46ed-83ad-2e6c21dee044",
   "metadata": {},
   "source": [
    "Dans cette partie, on construit un pipeline complet de mod√©lisation combinant toutes les √©tapes n√©cessaires : pr√©traitement, s√©lection de variables et apprentissage du mod√®le.\n",
    "\n",
    "Pipeline de r√©gression\n",
    "Le pipeline regressor int√®gre trois √©tapes cl√©s :\n",
    "\n",
    "Pr√©traitement : on applique le preprocessor pr√©c√©demment d√©fini, qui nettoie et transforme les variables num√©riques et cat√©gorielles.\n",
    "\n",
    "S√©lection de caract√©ristiques (RFE) : on utilise la m√©thode RFE (Recursive Feature Elimination) avec un mod√®le de r√©gression lin√©aire pour s√©lectionner automatiquement les 5 variables les plus pertinentes. Cela permet de simplifier le mod√®le tout en gardant un bon pouvoir pr√©dictif.\n",
    "\n",
    "Mod√®le de r√©gression : une r√©gression lin√©aire classique est entra√Æn√©e sur les variables s√©lectionn√©es pour pr√©dire le prix du logement.\n",
    "\n",
    "Pr√©paration des donn√©es d‚Äôapprentissage\n",
    "Ensuite, on d√©finit les entr√©es X comme les variables explicatives (num√©riques + cat√©gorielles) et la cible y comme le logarithme du prix + 1 (np.log1p(data['price'])). Ce choix permet de r√©duire l‚Äôimpact des valeurs extr√™mes et de stabiliser la variance du prix, qui est souvent tr√®s dispers√© dans les donn√©es Airbnb.\n",
    "\n",
    "S√©paration train/test\n",
    "On divise les donn√©es en un jeu d'entra√Ænement (80‚ÄØ%) et un jeu de test (20‚ÄØ%), ce qui permet de construire le mod√®le sur un sous-ensemble et d‚Äô√©valuer sa performance sur des donn√©es jamais vues, garantissant une √©valuation plus fiable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0147df-e47c-4199-b500-6fe489e135b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =====================\n",
    "# 7. GRID SEARCH POUR R√âGLAGE D‚ÄôHYPERPARAM√àTRES\n",
    "# =====================\n",
    "param_grid = {\n",
    "    'regressor__fit_intercept': [True, False]  # Tester si on inclut l'intercept dans le mod√®le\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(regressor, param_grid, cv=10, n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"\\n‚úÖ Meilleurs param√®tres trouv√©s : {grid_search.best_params_}\")\n",
    "\n",
    "# =====================\n",
    "# 8. √âVALUATION DU MOD√àLE\n",
    "# =====================\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"\\nüìä √âvaluation du mod√®le :\")\n",
    "print(f\" - RMSE (Root Mean Squared Error) : {rmse:.2f}\")\n",
    "print(f\" - MSE  (Mean Squared Error)      : {mse:.2f}\")\n",
    "print(f\" - MAE  (Mean Absolute Error)     : {mae:.2f}\")\n",
    "print(f\" - R¬≤   (Coefficient de d√©termination) : {r2:.3f}\")\n",
    "\n",
    "# Affichage de la matrice de corr√©lation des variables num√©riques\n",
    "corr_matrix = data[numeric_features].corr()\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')\n",
    "plt.title('Matrice de Corr√©lation des Variables Num√©riques')\n",
    "plt.show()\n",
    "\n",
    "# =====================\n",
    "# 9. ‚úÖ PR√âDICTION D‚ÄôUN NOUVEL AIRBNB\n",
    "# =====================\n",
    "# G√©n√©ration d'une annonce al√©atoire √† partir des distributions du dataset\n",
    "nouvelle_annonce = pd.DataFrame([{\n",
    "    'latitude': round(random.uniform(data['latitude'].min(), data['latitude'].max()), 4),\n",
    "    'longitude': round(random.uniform(data['longitude'].min(), data['longitude'].max()), 4),\n",
    "    'minimum_nights': random.randint(1, 30),\n",
    "    'number_of_reviews': random.randint(0, 100),\n",
    "    'reviews_per_month': round(random.uniform(0, 5), 2),\n",
    "    'neighbourhood': random.choice(data['neighbourhood'].dropna().unique()),\n",
    "    'room_type': random.choice(data['room_type'].dropna().unique())\n",
    "}])\n",
    "\n",
    "print(\"üè† Nouvelle annonce g√©n√©r√©e al√©atoirement :\\n\", nouvelle_annonce)\n",
    "\n",
    "# Pr√©diction du log(prix)\n",
    "log_price_pred = grid_search.predict(nouvelle_annonce)\n",
    "prix_estime = np.expm1(log_price_pred[0])  # Inverse de log1p ‚Üí on retrouve le prix r√©el\n",
    "\n",
    "\n",
    "print(f\"\\nüí∞ Prix estim√© pour la nouvelle annonce : {prix_estime:.2f} ‚Ç¨\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5729e495-9de5-455b-91c4-cf511d663734",
   "metadata": {},
   "source": [
    "Dans cette derni√®re partie, on affine le mod√®le, on l‚Äô√©value, puis on l‚Äôutilise pour estimer le prix d‚Äôune nouvelle annonce Airbnb.\n",
    "\n",
    "R√©glage des hyperparam√®tres (GridSearchCV)\n",
    "Un grid search est effectu√© pour tester automatiquement diff√©rentes valeurs de l‚Äôhyperparam√®tre fit_intercept du mod√®le de r√©gression lin√©aire (True ou False). Cela permet de d√©terminer si l‚Äôajout d‚Äôun terme constant (l‚Äôintercept) am√©liore les performances du mod√®le. La recherche est faite avec une validation crois√©e √† 10 plis (cv=10), assurant une √©valuation fiable de chaque configuration. Le meilleur param√®tre est ensuite affich√©.\n",
    "\n",
    "√âvaluation des performances\n",
    "Apr√®s entra√Ænement, le mod√®le est test√© sur le jeu de test. Plusieurs indicateurs de performance sont calcul√©s :\n",
    "\n",
    "RMSE : erreur quadratique moyenne racine, qui p√©nalise fortement les grosses erreurs.\n",
    "MAE : erreur absolue moyenne, qui donne une id√©e de l‚Äôerreur moyenne en euros.\n",
    "MSE : erreur quadratique moyenne brute.\n",
    "R¬≤ : coefficient de d√©termination, qui mesure la part de variance expliqu√©e par le mod√®le (proche de 1 = bon mod√®le).\n",
    "\n",
    "Un heatmap de la matrice de corr√©lation des variables num√©riques est √©galement g√©n√©r√©, permettant de visualiser les relations lin√©aires entre les variables (utile pour comprendre l'influence potentielle sur le prix).\n",
    "\n",
    "Pr√©diction sur une nouvelle annonce\n",
    "Enfin, une nouvelle annonce est g√©n√©r√©e al√©atoirement en s‚Äôinspirant des distributions pr√©sentes dans le dataset. Cette annonce fictive est ensuite pass√©e dans le pipeline entra√Æn√©, et le mod√®le pr√©dit le logarithme du prix. On applique alors la transformation inverse (expm1) pour retrouver un prix en euros, que l‚Äôon affiche comme estimation finale du loyer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd2e34c",
   "metadata": {},
   "source": [
    "## NOTES ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af15c96",
   "metadata": {},
   "source": [
    "L‚Äôanalyse des r√©sultats du mod√®le de r√©gression lin√©aire montre que le meilleur param√®tre trouv√© via la recherche par grille est `fit_intercept = True`, ce qui signifie que le mod√®le inclut un terme constant. Cela permet de mieux ajuster la droite de r√©gression aux donn√©es, en tenant compte d‚Äôun d√©calage √©ventuel de la moyenne des prix. En termes de performance, plusieurs m√©triques ont √©t√© utilis√©es pour √©valuer la qualit√© des pr√©dictions. Le RMSE est de 0.62, ce qui indique une erreur moyenne mod√©r√©e entre les prix pr√©dits et r√©els. Le MSE est de 0.38, ce qui va dans le m√™me sens. Le MAE, qui mesure l‚Äôerreur absolue moyenne, est de 0.47. Ces valeurs sont relativement correctes mais laissent entendre que le mod√®le peut √™tre am√©lior√©. Le R¬≤ est de 0.294, ce qui signifie que seulement 29,4 % de la variance des prix est expliqu√©e par le mod√®le. Cette valeur est assez faible, ce qui sugg√®re que des facteurs importants affectant le prix ne sont pas inclus dans le mod√®le.\n",
    "\n",
    "Pour tester la pr√©diction, une nouvelle annonce a √©t√© g√©n√©r√©e avec des caract√©ristiques al√©atoires. Elle correspond √† une chambre partag√©e situ√©e dans le quartier de Pullman, √† Chicago, avec 11 avis, 1.49 avis par mois, et une dur√©e minimale de s√©jour de 27 nuits. Le mod√®le a estim√© son prix √† 57.82 ‚Ç¨, ce qui semble coh√©rent avec une chambre partag√©e dans un quartier peu central, adapt√©e √† un public recherchant une solution √©conomique.\n",
    "\n",
    "Cependant, plusieurs limites sont apparentes. Le faible R¬≤ indique que le mod√®le est trop simple pour capturer la complexit√© des facteurs influen√ßant les prix Airbnb. Il pourrait √™tre am√©lior√© en ajoutant des variables plus pertinentes, comme la qualit√© des photos, la description de l‚Äôannonce, la saisonnalit√© ou encore la proximit√© des attractions touristiques. De plus, bien que la s√©lection des caract√©ristiques via RFE soit utile, elle peut ne pas suffire si certaines interactions entre variables ou non-lin√©arit√©s ne sont pas prises en compte. Enfin, l‚Äôutilisation de mod√®les plus avanc√©s comme les for√™ts al√©atoires ou le gradient boosting pourrait permettre d‚Äôaugmenter la pr√©cision des pr√©dictions en tenant compte de relations plus complexes dans les donn√©es. En somme, bien que le mod√®le fournisse des r√©sultats coh√©rents et une base solide, il existe une marge significative d‚Äôam√©lioration pour mieux mod√©liser les dynamiques de prix sur la plateforme Airbnb.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
