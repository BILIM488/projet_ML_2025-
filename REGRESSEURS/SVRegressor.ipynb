{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eae43369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 5 des configurations testées :\n",
      "     mean_test_score  std_test_score  param_regressor__C  \\\n",
      "66         -0.374055        0.005395                 1.0   \n",
      "60         -0.375257        0.005913                 1.0   \n",
      "72         -0.375623        0.004504                 1.0   \n",
      "129        -0.384205        0.006287               100.0   \n",
      "99         -0.384552        0.004383                10.0   \n",
      "\n",
      "     param_regressor__epsilon param_regressor__kernel param_regressor__gamma  \n",
      "66                       0.10                     rbf                  scale  \n",
      "60                       0.01                     rbf                  scale  \n",
      "72                       0.20                     rbf                  scale  \n",
      "129                      0.10                     rbf                   auto  \n",
      "99                       0.10                     rbf                   auto  \n",
      "\n",
      "MAE: 53.81\n",
      "RMSE: 115.87\n",
      "R²: 0.23\n",
      "\n",
      "Prix prédit pour la nouvelle annonce : 122.20 $ / 113.65 €\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from scipy.stats import zscore\n",
    "\n",
    "# Chargement des données\n",
    "data = pd.read_csv(\"listings.csv\")\n",
    "\n",
    "# Suppression des outliers (z-score > 3 sur 'price')\n",
    "data = data[(np.abs(zscore(data['price'])) < 3)]\n",
    "\n",
    "# Log-transformation des colonnes skewées\n",
    "skewed_cols = ['minimum_nights', 'number_of_reviews', 'reviews_per_month']\n",
    "for col in skewed_cols:\n",
    "    if col in data.columns:\n",
    "        data[col] = data[col].apply(lambda x: np.log1p(x))\n",
    "\n",
    "# Cible log-transformée\n",
    "y = np.log1p(data['price'])\n",
    "X = data.drop(columns=['price'])\n",
    "\n",
    "# Suppression des colonnes inutiles\n",
    "for col in ['name', 'last_review', 'host_name', 'neighbourhood_group']:\n",
    "    if col in X.columns:\n",
    "        X.drop(columns=col, inplace=True)\n",
    "\n",
    "# Colonnes numériques et catégorielles\n",
    "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_features = X.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Prétraitement\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Pipeline complet\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('feature_selection', SelectKBest(score_func=f_regression, k='all')),\n",
    "    ('regressor', SVR())\n",
    "])\n",
    "\n",
    "# Grille d'hyperparamètres\n",
    "param_grid = {\n",
    "    'regressor__C': [0.01, 0.1, 1, 10, 100],\n",
    "    'regressor__epsilon': [0.01, 0.1, 0.2, 0.5, 1],\n",
    "    'regressor__kernel': ['rbf', 'linear', 'poly'],\n",
    "    'regressor__gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "# Séparation train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Validation croisée\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=3, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Affichage des résultats de la validation croisée\n",
    "cv_results = pd.DataFrame(grid_search.cv_results_)\n",
    "cv_results = cv_results.sort_values(by=\"mean_test_score\", ascending=False)\n",
    "\n",
    "print(\"\\nTop 5 des configurations testées :\")\n",
    "print(cv_results[[\n",
    "    'mean_test_score', 'std_test_score',\n",
    "    'param_regressor__C',\n",
    "    'param_regressor__epsilon',\n",
    "    'param_regressor__kernel',\n",
    "    'param_regressor__gamma'\n",
    "]].head(5))\n",
    "\n",
    "# Meilleur modèle\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Évaluation\n",
    "y_pred_log = best_model.predict(X_test)\n",
    "y_pred = np.expm1(y_pred_log)\n",
    "y_test_exp = np.expm1(y_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test_exp, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test_exp, y_pred))\n",
    "r2 = r2_score(y_test_exp, y_pred)\n",
    "\n",
    "print(f\"\\nMAE: {mae:.2f}\")\n",
    "print(f\"RMSE: {rmse:.2f}\")\n",
    "print(f\"R²: {r2:.2f}\")\n",
    "\n",
    "# Prédiction sur une annonce\n",
    "sample = X_test.iloc[[0]]\n",
    "predicted_log_price = best_model.predict(sample)\n",
    "predicted_price_usd = np.expm1(predicted_log_price[0])\n",
    "predicted_price_eur = predicted_price_usd * 0.93\n",
    "\n",
    "print(f\"\\nPrix prédit pour la nouvelle annonce : {predicted_price_usd:.2f} $ / {predicted_price_eur:.2f} €\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7c9ff6",
   "metadata": {},
   "source": [
    "Chargement et nettoyage des données\n",
    "\n",
    "\n",
    "Lit les données du fichier listings.csv.\n",
    "\n",
    "Supprime les outliers sur la colonne price en appliquant un z-score > 3.\n",
    "\n",
    "\n",
    "Applique une transformation logarithmique (log1p) sur les colonnes très asymétriques :\n",
    "minimum_nights, number_of_reviews, reviews_per_month.\n",
    "\n",
    "\n",
    "\n",
    "2. Préparation des variables\n",
    "La variable cible price est également log-transformée (y = log1p(price)).\n",
    "\n",
    "Supprime les colonnes inutiles ou non pertinentes comme name, host_name, last_review, neighbourhood_group.\n",
    "\n",
    "\n",
    "\n",
    "3. Prétraitement des données\n",
    "Crée un pipeline de transformation pour :\n",
    "\n",
    "les colonnes numériques : imputation (médiane) + standardisation.\n",
    "\n",
    "les colonnes catégorielles : imputation (valeur fréquente) + encodage OneHot.\n",
    "\n",
    "Combine tout cela dans un ColumnTransformer.\n",
    "\n",
    "\n",
    "\n",
    "4. Pipeline complet\n",
    "Le pipeline applique :\n",
    "\n",
    "Le prétraitement.\n",
    "\n",
    "Une sélection de caractéristiques (ici, toutes sont conservées avec k='all').\n",
    "\n",
    "Un modèle de régression par SVM (SVR).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "5. Optimisation par validation croisée\n",
    "Utilise GridSearchCV avec une grille d’hyperparamètres (C, epsilon, kernel, gamma).\n",
    "\n",
    "Score utilisé : MAE négatif (pour le minimiser).\n",
    "\n",
    "Validation croisée avec 3 plis (cv=3).\n",
    "\n",
    "\n",
    "\n",
    "6. Évaluation finale\n",
    "Utilise le meilleur modèle trouvé pour prédire les prix sur un jeu de test.\n",
    "\n",
    "Retransforme les valeurs (expm1) pour revenir aux prix réels en dollars.\n",
    "\n",
    "Calcule les métriques :\n",
    "\n",
    "MAE (erreur absolue moyenne),\n",
    "\n",
    "RMSE (erreur quadratique moyenne),\n",
    "\n",
    "R² (coefficient de détermination).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "7. Prédiction sur une annonce\n",
    "Prédit le prix d’un logement tiré de l’échantillon test.\n",
    "\n",
    "Affiche le prix estimé en dollars et en euros (conversion à 0,93 €/USD)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9e52c0",
   "metadata": {},
   "source": [
    "Le meilleur MAE moyen est 0.374 sur les données log-transformées (base e).\n",
    "\n",
    "L’écart type faible (~0.005) indique une bonne stabilité du modèle durant la validation croisée\n",
    "\n",
    "Évaluation sur l’ensemble de test (prix réels)\n",
    "\n",
    "\n",
    "\n",
    "MAE : 53.81 € l'erreur moyenne absolue est d'environ 54 € par annonce.\n",
    "\n",
    "RMSE : 115.87 €  l'erreur moyenne est plus sévère sur les grandes valeurs.\n",
    "\n",
    "R² : 0.23 → le modèle n’explique que 23 % de la variance des prix réels.\n",
    "\n",
    " Cela montre une perte de performance importante entre validation croisée (sur données transformées) et test final (prix réels)\n",
    "\n",
    " Limites du modèle actuel\n",
    "\n",
    "\n",
    "\n",
    "Perte d’interprétabilité à cause de la transformation logarithmique.\n",
    "\n",
    "Bien qu’elle stabilise la variance, elle rend les erreurs finales plus difficiles à interpréter directement.\n",
    "\n",
    "SVM peu performant avec des grands jeux de données hétérogènes :\n",
    "\n",
    "Surtout avec des variables catégorielles encodées OneHot (augmentation de la dimension).\n",
    "\n",
    "Temps de calcul élevé pour la grille SVR.\n",
    "\n",
    "Score R² faible (0.23) :\n",
    "\n",
    "Le modèle ne capture pas bien les facteurs influents du prix.\n",
    "\n",
    "Potentiel sous-apprentissage (underfitting).\n",
    "\n",
    "Pas de traitement des interactions non linéaires entre les variables :\n",
    "\n",
    "Le modèle RBF peut les détecter, mais pas efficacement avec peu de tuning ou avec beaucoup de bruit.\n",
    "\n",
    "Données potentiellement déséquilibrées ou bruitées :\n",
    "\n",
    "Prix Airbnb souvent très variables selon des critères qualitatifs (photos, description, réputation)\n",
    "\n",
    "\n",
    " Améliorations possibles\n",
    "\n",
    "\n",
    " \n",
    "Tester d'autres modèles plus robustes :\n",
    "\n",
    "Random Forest, Gradient Boosting (XGBoost, LightGBM) ou HistGradientBoostingRegressor.\n",
    "\n",
    "Ces modèles gèrent mieux les interactions et les données hétérogènes.\n",
    "\n",
    "Réduction de dimension (PCA) ou sélection automatique de variables :\n",
    "\n",
    "Réduit la complexité et le surapprentissage possible dû à OneHotEncoder.\n",
    "\n",
    "Feature engineering plus riche :\n",
    "\n",
    "Créer de nouvelles variables comme : score d’évaluation par nuit, taux d’occupation, etc.\n",
    "\n",
    "Traitement avancé des catégories :\n",
    "\n",
    "Utiliser Target Encoding au lieu de OneHot pour les grosses colonnes catégorielles.\n",
    "\n",
    "Augmenter les folds de validation croisée :\n",
    "\n",
    "Passer à 5 ou 10 folds pour une meilleure estimation de la variance.\n",
    "\n",
    "Exploration de modèles basés sur deep learning (si suffisamment de données et de ressources).\n",
    "\n",
    "\n",
    " Conclusion\n",
    "\n",
    "\n",
    " \n",
    "Le modèle SVM testé ici, bien que stable lors de la validation croisée, n’offre pas des performances satisfaisantes en production sur des prix Airbnb réels. L’erreur moyenne de 54 € reste élevée, et la faible valeur de R² (0.23) indique que le modèle ne parvient pas à bien modéliser la complexité des prix de location.\n",
    "Des modèles plus adaptés comme les arbres de décision ensemblistes pourraient fortement améliorer la qualité prédictive tout en conservant une certaine robustesse face aux données bruitées.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ML 2025)",
   "language": "python",
   "name": "ml-project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
