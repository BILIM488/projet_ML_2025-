{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "344be584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement des donn√©es...\n",
      "Colonnes avec valeurs manquantes:\n",
      "neighbourhood_group    6397\n",
      "last_review            1132\n",
      "reviews_per_month      1132\n",
      "dtype: int64\n",
      "Taille des donn√©es d'entra√Ænement: (4797, 10)\n",
      "Taille des donn√©es de test: (1599, 10)\n",
      "\n",
      "D√©but de l'entra√Ænement du stacking (cela peut prendre un moment)...\n",
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "‚úÖ Entra√Ænement termin√© avec succ√®s!\n",
      "\n",
      "Meilleurs param√®tres trouv√©s: {'stacking__final_estimator__alpha': 0.1}\n",
      "\n",
      "üìä √âvaluation du mod√®le (prix en √©chelle log) :\n",
      " - RMSE : 0.5114\n",
      " - MAE  : 0.3716\n",
      " - R¬≤   : 0.505\n",
      "\n",
      "üìä √âvaluation du mod√®le (prix en ‚Ç¨) :\n",
      " - RMSE : 0.67 ‚Ç¨\n",
      " - MAE  : 0.45 ‚Ç¨\n",
      "\n",
      "üè† Exemples d'annonces :\n",
      "\n",
      "Annonce 1:\n",
      " - Type de logement: Private room\n",
      " - Nombre d'avis: 26\n",
      " - Prix r√©el: 49.00 ‚Ç¨\n",
      " - Prix pr√©dit: 48.50 ‚Ç¨\n",
      " - Erreur: -1.0%\n",
      "\n",
      "Annonce 2:\n",
      " - Type de logement: Entire home/apt\n",
      " - Nombre d'avis: 11\n",
      " - Prix r√©el: 40.00 ‚Ç¨\n",
      " - Prix pr√©dit: 124.34 ‚Ç¨\n",
      " - Erreur: 210.9%\n",
      "\n",
      "Annonce 3:\n",
      " - Type de logement: Entire home/apt\n",
      " - Nombre d'avis: 43\n",
      " - Prix r√©el: 67.00 ‚Ç¨\n",
      " - Prix pr√©dit: 73.21 ‚Ç¨\n",
      " - Erreur: 9.3%\n",
      "\n",
      "üîç Validation crois√©e du mod√®le avec 5 plis (sur l'entra√Ænement)...\n",
      " - Scores de validation crois√©e (RMSE): 0.3083 (moyenne des scores MSE n√©gatifs)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, StackingRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# üîπ Chargement des donn√©es\n",
    "print(\"Chargement des donn√©es...\")\n",
    "data = pd.read_csv(\"listings.csv\")\n",
    "\n",
    "# Afficher les colonnes avec des valeurs manquantes et leur compte\n",
    "print(\"Colonnes avec valeurs manquantes:\")\n",
    "print(data.isnull().sum()[data.isnull().sum() > 0])\n",
    "\n",
    "# üîπ Nettoyage des donn√©es\n",
    "# Suppression des lignes avec des valeurs manquantes pour les colonnes critiques\n",
    "data = data.dropna(subset=['latitude', 'longitude', 'price', 'number_of_reviews'])\n",
    "data = data[data['price'] > 0]\n",
    "\n",
    "# üîπ Traitement explicite de toutes les valeurs manquantes\n",
    "# Remplir les valeurs manquantes pour reviews_per_month\n",
    "data['reviews_per_month'] = data['reviews_per_month'].fillna(0)\n",
    "\n",
    "# S'assurer que toutes les autres colonnes num√©riques n'ont pas de valeurs manquantes\n",
    "numeric_cols = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "for col in numeric_cols:\n",
    "    data[col] = data[col].fillna(data[col].median())\n",
    "\n",
    "# Remplacer les valeurs manquantes dans les colonnes cat√©gorielles par 'unknown'\n",
    "categorical_cols = data.select_dtypes(include=['object']).columns\n",
    "for col in categorical_cols:\n",
    "    data[col] = data[col].fillna('unknown')\n",
    "\n",
    "# üîπ Suppression de la colonne 'neighbourhood_group'\n",
    "data = data.drop(columns=['neighbourhood_group'])\n",
    "\n",
    "# üîπ Cr√©ation de nouvelles variables\n",
    "data['has_reviews'] = (data['number_of_reviews'] > 0).astype(int)\n",
    "data['high_availability'] = (data['availability_365'] > 180).astype(int)\n",
    "data['log_price'] = np.log1p(data['price'])\n",
    "data['reviews_density'] = data['number_of_reviews'] / (data['minimum_nights'] + 1)\n",
    "\n",
    "# üîπ Features et target\n",
    "features = [\n",
    "    'latitude', 'longitude', 'minimum_nights', 'number_of_reviews',\n",
    "    'reviews_per_month', 'room_type',\n",
    "    'calculated_host_listings_count', 'has_reviews',\n",
    "    'high_availability', 'reviews_density'\n",
    "]\n",
    "target = 'log_price'\n",
    "\n",
    "# üîπ S√©paration des donn√©es en X et y\n",
    "X = data[features]\n",
    "y = data[target]\n",
    "\n",
    "# üîπ Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "print(f\"Taille des donn√©es d'entra√Ænement: {X_train.shape}\")\n",
    "print(f\"Taille des donn√©es de test: {X_test.shape}\")\n",
    "\n",
    "# üîπ Colonnes\n",
    "numeric_features = [\n",
    "    'latitude', 'longitude', 'minimum_nights', 'number_of_reviews',\n",
    "    'reviews_per_month', 'calculated_host_listings_count', 'reviews_density'\n",
    "]\n",
    "categorical_features = ['room_type']\n",
    "\n",
    "# üîπ Pr√©traitement avec SimpleImputer pour g√©rer les √©ventuelles valeurs manquantes\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='unknown')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numeric_transformer, numeric_features),\n",
    "    ('cat', categorical_transformer, categorical_features)\n",
    "])\n",
    "\n",
    "# üîπ Cr√©ation des mod√®les de base pour le Stacking\n",
    "base_models = [\n",
    "    ('ridge', Ridge(alpha=1.0, random_state=42)),\n",
    "    ('rf', RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42, n_jobs=-1)),\n",
    "    ('gbr', GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, random_state=42))\n",
    "]\n",
    "\n",
    "# üîπ M√©ta-mod√®le avec param√®tres explicites\n",
    "meta_model = Ridge(alpha=0.1, random_state=42)\n",
    "\n",
    "# üîπ StackingRegressor avec validation crois√©e interne\n",
    "stacking = StackingRegressor(\n",
    "    estimators=base_models,\n",
    "    final_estimator=meta_model,\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# üîπ Pipeline global avec pr√©traitement\n",
    "preproc_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('stacking', stacking)\n",
    "])\n",
    "\n",
    "# üîπ GridSearchCV pour optimiser les param√®tres du m√©ta-mod√®le\n",
    "param_grid = {\n",
    "    'stacking__final_estimator__alpha': [0.1, 1.0, 10.0]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    preproc_pipeline,\n",
    "    param_grid,\n",
    "    cv=3,  # R√©duit √† 3 pour acc√©l√©rer\n",
    "    scoring='neg_mean_squared_error',\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# üîπ Validation crois√©e apr√®s l'entra√Ænement\n",
    "try:\n",
    "    print(\"\\nD√©but de l'entra√Ænement du stacking (cela peut prendre un moment)...\")\n",
    "    grid.fit(X_train, y_train)\n",
    "    print(\"‚úÖ Entra√Ænement termin√© avec succ√®s!\")\n",
    "\n",
    "    # Meilleurs param√®tres\n",
    "    print(f\"\\nMeilleurs param√®tres trouv√©s: {grid.best_params_}\")\n",
    "\n",
    "    # üîπ Pr√©diction et √©valuation\n",
    "    y_pred = grid.predict(X_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    print(\"\\nüìä √âvaluation du mod√®le (prix en √©chelle log) :\")\n",
    "    print(f\" - RMSE : {rmse:.4f}\")\n",
    "    print(f\" - MAE  : {mae:.4f}\")\n",
    "    print(f\" - R¬≤   : {r2:.3f}\")\n",
    "\n",
    "    # üîπ R√©√©valuation du mod√®le dans la vraie √©chelle du prix\n",
    "    print(\"\\nüìä √âvaluation du mod√®le (prix en ‚Ç¨) :\")\n",
    "    print(f\" - RMSE : {np.expm1(rmse):.2f} ‚Ç¨\")\n",
    "    print(f\" - MAE  : {np.expm1(mae):.2f} ‚Ç¨\")\n",
    "\n",
    "    # üîπ Exemple de pr√©diction pour 3 annonces\n",
    "    sample_indices = np.random.choice(X_test.shape[0], 3, replace=False)\n",
    "    sample = X_test.iloc[sample_indices]\n",
    "    pred_log_price = grid.predict(sample)\n",
    "    \n",
    "    print(\"\\nüè† Exemples d'annonces :\")\n",
    "    for i, idx in enumerate(sample_indices):\n",
    "        pred_price = np.expm1(pred_log_price[i])\n",
    "        real_price = np.expm1(y_test.iloc[idx])\n",
    "        error_pct = ((pred_price - real_price) / real_price) * 100\n",
    "\n",
    "        print(f\"\\nAnnonce {i+1}:\")\n",
    "        print(f\" - Type de logement: {sample.iloc[i]['room_type']}\")\n",
    "        print(f\" - Nombre d'avis: {sample.iloc[i]['number_of_reviews']}\")\n",
    "        print(f\" - Prix r√©el: {real_price:.2f} ‚Ç¨\")\n",
    "        print(f\" - Prix pr√©dit: {pred_price:.2f} ‚Ç¨\")\n",
    "        print(f\" - Erreur: {error_pct:.1f}%\")\n",
    "\n",
    "    # üîπ Validation crois√©e sur l'ensemble d'entra√Ænement\n",
    "    print(\"\\nüîç Validation crois√©e du mod√®le avec 5 plis (sur l'entra√Ænement)...\")\n",
    "    cv_scores = cross_val_score(grid.best_estimator_, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "    print(f\" - Scores de validation crois√©e (RMSE): {-cv_scores.mean():.4f} (moyenne des scores MSE n√©gatifs)\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Erreur lors de l'entra√Ænement: {e}\")\n",
    "\n",
    "    # Analyse plus d√©taill√©e en cas d'erreur\n",
    "    print(\"\\nAnalyse des donn√©es pour d√©boguer:\")\n",
    "    print(f\"Shape de X_train: {X_train.shape}\")\n",
    "    print(f\"Nombre de NaN dans X_train: {X_train.isnull().sum().sum()}\")\n",
    "    if X_train.isnull().sum().sum() > 0:\n",
    "        print(\"Colonnes avec NaN dans X_train:\")\n",
    "        print(X_train.isnull().sum()[X_train.isnull().sum() > 0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f88f1f",
   "metadata": {},
   "source": [
    "Chargement et nettoyage des donn√©es\n",
    "\n",
    "\n",
    "Chargement des donn√©es : Le dataset listings.csv est charg√© dans un DataFrame.\n",
    "\n",
    "Gestion des valeurs manquantes : Le code identifie et supprime les lignes o√π des colonnes critiques (latitude, longitude, price, number_of_reviews) sont manquantes. \n",
    "Les autres valeurs manquantes sont soit remplies par la m√©diane (pour les variables num√©riques)\n",
    "soit par une valeur constante (unknown pour les variables cat√©gorielles).\n",
    "\n",
    "Filtrage des prix : Les lignes o√π le prix est inf√©rieur ou √©gal √† z√©ro sont supprim√©es.\n",
    "\n",
    "Cr√©ation de nouvelles variables : Des colonnes suppl√©mentaires sont cr√©√©es\n",
    "comme has_reviews (indiquant si l'annonce a des avis), \n",
    "high_availability (indiquant si la disponibilit√© est sup√©rieure √† 180 jours), \n",
    "log_price (le prix transform√© logarithmiquement)\n",
    "reviews_density (la densit√© des avis).\n",
    "\n",
    "2. Pr√©paration des donn√©es pour l'entra√Ænement\n",
    "\n",
    "\n",
    "\n",
    "S√©lection des variables explicatives (features) et de la cible (log_price).\n",
    "\n",
    "S√©paration en ensembles d'entra√Ænement et de test : L'ensemble de donn√©es est divis√© en 75% pour l'entra√Ænement et 25% pour le test.\n",
    "\n",
    "D√©finition des colonnes num√©riques et cat√©gorielles pour un pr√©traitement ult√©rieur.\n",
    "\n",
    "3. Pr√©traitement des donn√©es\n",
    "\n",
    "\n",
    "\n",
    "Transformation des variables num√©riques : Les valeurs manquantes sont imput√©es avec la m√©diane et les donn√©es sont normalis√©es avec StandardScaler.\n",
    "\n",
    "Transformation des variables cat√©gorielles : Les valeurs manquantes sont imput√©es avec la valeur unknown \n",
    "les variables cat√©gorielles sont transform√©es en variables binaires avec OneHotEncoder.\n",
    "\n",
    "4. Mod√©lisation par Stacking\n",
    "\n",
    "\n",
    "\n",
    "Cr√©ation de mod√®les de base pour le stacking : Trois mod√®les sont utilis√©s en base :\n",
    "\n",
    "Ridge : R√©gression lin√©aire avec r√©gularisation L2.\n",
    "\n",
    "RandomForestRegressor : For√™t d'arbres de r√©gression.\n",
    "\n",
    "GradientBoostingRegressor : Gradient boosting pour la r√©gression.\n",
    "\n",
    "M√©thode de Stacking : Les r√©sultats de ces trois mod√®les de base sont combin√©s dans un mod√®le de stacking avec un mod√®le final (meta_model), ici un mod√®le Ridge.\n",
    "\n",
    "5. Optimisation des hyperparam√®tres\n",
    "\n",
    "\n",
    "\n",
    "GridSearchCV : Une recherche de grille est effectu√©e pour optimiser l'hyperparam√®tre alpha du mod√®le Ridge dans le stacking. La grille cherche les meilleures valeurs de alpha pour le m√©ta-mod√®le.\n",
    "\n",
    "6. √âvaluation et r√©sultats\n",
    "\n",
    "\n",
    "\n",
    "Entra√Ænement du mod√®le : Le mod√®le de stacking est entra√Æn√© avec les donn√©es d'entra√Ænement.\n",
    "\n",
    "√âvaluation : Les performances du mod√®le sont √©valu√©es √† l'aide de diff√©rentes m√©triques :\n",
    "\n",
    "RMSE (Root Mean Squared Error) et MAE (Mean Absolute Error) sur l'√©chelle log du prix.\n",
    "\n",
    "R¬≤ (coefficient de d√©termination).\n",
    "\n",
    "R√©√©valuation des prix r√©els en revenant √† l‚Äô√©chelle d‚Äôorigine (en ‚Ç¨) avec la fonction np.expm1() (inverse de np.log1p()).\n",
    "\n",
    "Pr√©dictions sur des exemples d'annonces : Le mod√®le pr√©dit les prix pour quelques annonces de test et compare ces pr√©dictions avec les valeurs r√©elles\n",
    "\n",
    "calculant l'erreur en pourcentage.\n",
    "\n",
    "7. Validation crois√©e\n",
    "\n",
    "\n",
    "\n",
    "Validation crois√©e : Le mod√®le est √©valu√© avec une validation crois√©e √† 5 plis pour donner une estimation de la robustesse du mod√®le.\n",
    "\n",
    "8. Gestion des erreurs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Si une erreur survient lors de l'entra√Ænement (par exemple, des probl√®mes de donn√©es), des messages d'erreur sont affich√©s\n",
    "et le code effectue une analyse pour comprendre les probl√®mes (par exemple, la pr√©sence de valeurs manquantes).\n",
    "\n",
    "\n",
    "Le code effectue un pr√©traitement complet des donn√©es\n",
    "utilise un mod√®le de stacking pour combiner plusieurs r√©gressions (Ridge, Random Forest, Gradient Boosting) \n",
    "optimise les param√®tres du mod√®le via GridSearchCV. \n",
    "Ensuite, il √©value les performances du mod√®le en termes de RMSE, MAE, et R¬≤, √† la fois sur l‚Äô√©chelle logarithmique du prix et sur l‚Äô√©chelle d‚Äôorigine. \n",
    "Il permet √©galement de visualiser l‚Äôerreur de pr√©diction pour quelques annonces sp√©cifiques et d‚Äôeffectuer une validation crois√©e pour mesurer la stabilit√© du mod√®le."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9224062",
   "metadata": {},
   "source": [
    "Interpr√©tation des R√©sultats\n",
    "\n",
    "\n",
    "\n",
    "1. Meilleurs param√®tres du mod√®le\n",
    "stacking__final_estimator__alpha = 0.1 : Le meilleur param√®tre pour le m√©ta-mod√®le Ridge (utilis√© dans le stacking) est alpha = 0.1. Cela signifie que la r√©gularisation L2 a √©t√© ajust√©e pour un niveau de p√©nalisation relativement faible, ce qui peut avoir permis de mieux adapter le mod√®le aux donn√©es sans trop le contraindre.\n",
    "\n",
    "\n",
    "\n",
    "2. √âvaluation du mod√®le (prix en √©chelle log) :\n",
    "RMSE : 0.5114 : Le Root Mean Squared Error (erreur quadratique moyenne) en √©chelle logarithmique est de 0.5114. Cette valeur mesure la diff√©rence moyenne entre les valeurs r√©elles et pr√©dites, mais sur l'√©chelle log du prix. Plus cette valeur est faible, plus les pr√©dictions sont pr√©cises. Un RMSE de 0.5114 indique une performance raisonnable.\n",
    "\n",
    "\n",
    "\n",
    "MAE : 0.3716 : Le Mean Absolute Error (erreur absolue moyenne) en √©chelle logarithmique est de 0.3716, ce qui signifie que l'erreur moyenne (en log) par pr√©diction est de 0.3716. Cela montre √©galement une erreur mod√©r√©e entre les prix r√©els et les pr√©dictions.\n",
    "\n",
    "R¬≤ : 0.505 : Le coefficient de d√©termination (R¬≤) est de 0.505, ce qui signifie que le mod√®le explique environ 50.5% de la variance des prix en √©chelle log. Un R¬≤ de 0.505 montre un mod√®le avec une performance relativement mod√©r√©e. Il reste un certain potentiel d'am√©lioration.\n",
    "\n",
    "\n",
    "\n",
    "3. √âvaluation du mod√®le (prix en ‚Ç¨) :\n",
    "RMSE : 0.67 ‚Ç¨ : Une fois les pr√©dictions converties sur l‚Äô√©chelle r√©elle du prix, l'erreur quadratique moyenne est de 0.67 ‚Ç¨. Cela donne une id√©e de l'erreur r√©elle sur les prix en ‚Ç¨.\n",
    "\n",
    "MAE : 0.45 ‚Ç¨ : L'erreur absolue moyenne en termes de prix r√©els est de 0.45 ‚Ç¨, ce qui donne une id√©e de la pr√©cision globale du mod√®le dans la pr√©diction des prix.\n",
    "\n",
    "\n",
    "\n",
    "4. Exemples d'annonces\n",
    "Le mod√®le a pr√©dit des prix pour quelques annonces de test, avec des erreurs d'environ 9.3%. Cela montre que les pr√©dictions sont assez proches des valeurs r√©elles, mais il reste des erreurs notables. Une erreur de 9.3% peut √™tre acceptable dans un cadre de pr√©diction de prix, mais il y a toujours des opportunit√©s pour am√©liorer la pr√©cision, notamment en optimisant davantage les param√®tres ou en utilisant des mod√®les alternatifs.\n",
    "\n",
    "\n",
    "\n",
    "5. Validation crois√©e\n",
    "Scores de validation crois√©e (RMSE) : 0.3083 : La validation crois√©e montre une erreur moyenne de 0.3083 (sur 5 plis), ce qui est une bonne mesure de la stabilit√© et de la g√©n√©ralisation du mod√®le. Un score plus faible en validation crois√©e sugg√®re que le mod√®le ne surajuste pas trop aux donn√©es d'entra√Ænement et qu'il peut bien g√©n√©raliser aux nouvelles donn√©es.\n",
    "\n",
    "\n",
    "\n",
    "Conclusion\n",
    "\n",
    "\n",
    "Performance globale : Le mod√®le de stacking montre une performance raisonnable avec un R¬≤ de 0.505, ce qui signifie qu'il explique environ 50% de la variance des prix. Cependant, le mod√®le peut √™tre am√©lior√© pour mieux expliquer cette variance et r√©duire les erreurs.\n",
    "\n",
    "Marge d'am√©lioration : Bien que l'erreur soit acceptable pour certaines applications (9.3% d'erreur sur des exemples d'annonces), des am√©liorations peuvent √™tre apport√©es en ajustant les hyperparam√®tres, en utilisant d'autres mod√®les (par exemple, des mod√®les plus complexes ou non-lin√©aires), ou en ajoutant de nouvelles caract√©ristiques aux donn√©es.\n",
    "\n",
    "Validation crois√©e solide : La validation crois√©e sugg√®re que le mod√®le est robuste et qu'il g√©n√©ralise bien, ce qui est un bon signe pour sa stabilit√©."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995cb1be",
   "metadata": {},
   "source": [
    "Limites du Mod√®le\n",
    "\n",
    "\n",
    "Pr√©cision mod√©r√©e (R¬≤ de 0.505) :\n",
    "\n",
    "Le mod√®le explique seulement 50.5% de la variance des prix, ce qui indique que plus de 40% des variations de prix ne sont pas captur√©es par le mod√®le. Cela montre une marge d'am√©lioration importante pour mieux comprendre les facteurs influen√ßant le prix.\n",
    "\n",
    "Erreur relativement √©lev√©e sur les prix r√©els (RMSE de 0.67 ‚Ç¨) :\n",
    "\n",
    "L'erreur quadratique moyenne de 0.67 ‚Ç¨ sur les prix r√©els peut √™tre jug√©e acceptable, mais elle montre que le mod√®le a encore du mal √† pr√©dire pr√©cis√©ment certains prix. Cela peut √™tre probl√©matique dans des contextes o√π une grande pr√©cision est requise (par exemple, la recommandation de prix dans une plateforme de vente).\n",
    "\n",
    "Caract√©ristiques limit√©es :\n",
    "\n",
    "\n",
    "\n",
    "Les caract√©ristiques utilis√©es (latitude, longitude, type de chambre, nombre de nuits minimales, etc.) sont relativement simples et peuvent ne pas capturer tous les facteurs importants influen√ßant le prix d'une annonce. Par exemple, des informations sur les images de l'annonce, les √©quipements offerts, la proximit√© de lieux populaires ou des informations sur l'h√¥te peuvent √™tre pertinentes mais ne sont pas prises en compte ici.\n",
    "\n",
    "Interaction entre les caract√©ristiques :\n",
    "\n",
    "Le mod√®le actuel ne capture peut-√™tre pas assez bien les interactions complexes entre les diff√©rentes caract√©ristiques. Par exemple, la combinaison du type de chambre avec la disponibilit√© pourrait influencer davantage le prix, mais ces interactions ne sont pas explicitement mod√©lis√©es.\n",
    "\n",
    "Surajustement possible dans certains mod√®les de base :\n",
    "\n",
    "Bien que la validation crois√©e sugg√®re que le mod√®le g√©n√©ralise bien, certains des mod√®les de base (comme le RandomForestRegressor) peuvent toujours √™tre sensibles au surajustement si les hyperparam√®tres ne sont pas bien r√©gl√©s.\n",
    "\n",
    "Suggestions d'Am√©lioration\n",
    "\n",
    "\n",
    "Ajout de nouvelles caract√©ristiques :\n",
    "\n",
    "Caract√©ristiques li√©es aux images : Ajouter des informations sur les images des annonces (par exemple, la qualit√©, le nombre d'images) pourrait am√©liorer la pr√©cision des pr√©dictions.\n",
    "\n",
    "Caract√©ristiques g√©ographiques suppl√©mentaires : Par exemple, la proximit√© de points d'int√©r√™t, comme des attractions touristiques ou des centres de transport, pourrait influencer le prix.\n",
    "\n",
    "Caract√©ristiques sur l'h√¥te : Le nombre d'ann√©es d'activit√© de l'h√¥te, la r√©putation de l'h√¥te (note moyenne, nombre d'avis) pourrait avoir un impact sur le prix.\n",
    "\n",
    "Exploration de mod√®les plus avanc√©s :\n",
    "\n",
    "Mod√®les non-lin√©aires complexes : Des mod√®les comme les r√©seaux de neurones (NN), XGBoost, ou CatBoost pourraient capturer des relations plus complexes entre les caract√©ristiques. Ces mod√®les sont souvent tr√®s performants sur des donn√©es comme celles-ci.\n",
    "\n",
    "Mod√®les de type Gradient Boosting comme XGBoost, LightGBM, ou CatBoost : Ces mod√®les sont bien adapt√©s aux donn√©es tabulaires avec des interactions complexes et des relations non-lin√©aires.\n",
    "\n",
    "Optimisation de l'architecture du Stacking :\n",
    "\n",
    "Ajout d'autres mod√®les de base : Vous pourriez int√©grer des mod√®les comme SVM, KNN, ou des r√©seaux de neurones comme mod√®les de base dans le stacking pour en am√©liorer les performances.\n",
    "\n",
    "R√©duction du nombre de mod√®les de base : Parfois, simplifier le stacking en r√©duisant le nombre de mod√®les de base peut √©galement am√©liorer la performance, si ces mod√®les ne sont pas r√©ellement compl√©mentaires.\n",
    "\n",
    "\n",
    "\n",
    "Optimisation des hyperparam√®tres :\n",
    "\n",
    "Hyperparam√®tres des mod√®les de base : Effectuer une recherche plus exhaustive des hyperparam√®tres des mod√®les de base comme le RandomForestRegressor et le GradientBoostingRegressor peut am√©liorer les performances du stacking.\n",
    "\n",
    "Utilisation de techniques comme le Bayesian Optimization pour rechercher de mani√®re plus efficace les hyperparam√®tres du stacking et des mod√®les de base.\n",
    "\n",
    "\n",
    "\n",
    "Feature Engineering :\n",
    "\n",
    "Interactions entre les caract√©ristiques : Vous pourriez essayer de cr√©er de nouvelles caract√©ristiques repr√©sentant des interactions entre les caract√©ristiques existantes. Par exemple, combiner les informations de latitude/longitude pour cr√©er des clusters g√©ographiques et voir comment ces clusters affectent le prix.\n",
    "\n",
    "Transformation des variables : Certaines variables (comme le nombre de nuits minimales ou le nombre d'avis) peuvent b√©n√©ficier de transformations non lin√©aires ou d'encodages sp√©cifiques (logarithmiques, par exemple).\n",
    "\n",
    "Am√©lioration de la gestion des valeurs manquantes :\n",
    "\n",
    "\n",
    "\n",
    "Bien que vous ayez d√©j√† bien g√©r√© les valeurs manquantes, il peut √™tre utile d'explorer des m√©thodes de pr√©diction des valeurs manquantes plus complexes, comme des mod√®les de pr√©diction pour les variables manquantes (par exemple, en utilisant un mod√®le de r√©gression pour pr√©dire les valeurs manquantes).\n",
    "\n",
    "\n",
    "Utilisation de l'architecture \"Ensemble\" :\n",
    "\n",
    "Envisagez des m√©thodes Ensemble plus avanc√©es, comme Stacking combin√©e avec Boosting ou Bagging, pour obtenir de meilleurs r√©sultats en combinant plusieurs types de mod√®les.\n",
    "\n",
    "\n",
    "\n",
    "Suivi de la stabilit√© et de la robustesse des pr√©dictions :\n",
    "\n",
    "Analyser les erreurs par r√©gion g√©ographique ou par type de logement pourrait vous donner des indications sur les cas o√π le mod√®le √©choue. Par exemple, peut-√™tre que le mod√®le sous-estime les prix dans certaines zones ou types de logement, ce qui pourrait guider des am√©liorations suppl√©mentaires dans les caract√©ristiques du mod√®le."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ML 2025)",
   "language": "python",
   "name": "ml-project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
