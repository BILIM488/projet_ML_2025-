{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "344be584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement des données...\n",
      "Colonnes avec valeurs manquantes:\n",
      "neighbourhood_group    6397\n",
      "last_review            1132\n",
      "reviews_per_month      1132\n",
      "dtype: int64\n",
      "Taille des données d'entraînement: (4797, 10)\n",
      "Taille des données de test: (1599, 10)\n",
      "\n",
      "Début de l'entraînement du stacking (cela peut prendre un moment)...\n",
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "✅ Entraînement terminé avec succès!\n",
      "\n",
      "Meilleurs paramètres trouvés: {'stacking__final_estimator__alpha': 0.1}\n",
      "\n",
      "📊 Évaluation du modèle (prix en échelle log) :\n",
      " - RMSE : 0.5114\n",
      " - MAE  : 0.3716\n",
      " - R²   : 0.505\n",
      "\n",
      "📊 Évaluation du modèle (prix en €) :\n",
      " - RMSE : 0.67 €\n",
      " - MAE  : 0.45 €\n",
      "\n",
      "🏠 Exemples d'annonces :\n",
      "\n",
      "Annonce 1:\n",
      " - Type de logement: Private room\n",
      " - Nombre d'avis: 26\n",
      " - Prix réel: 49.00 €\n",
      " - Prix prédit: 48.50 €\n",
      " - Erreur: -1.0%\n",
      "\n",
      "Annonce 2:\n",
      " - Type de logement: Entire home/apt\n",
      " - Nombre d'avis: 11\n",
      " - Prix réel: 40.00 €\n",
      " - Prix prédit: 124.34 €\n",
      " - Erreur: 210.9%\n",
      "\n",
      "Annonce 3:\n",
      " - Type de logement: Entire home/apt\n",
      " - Nombre d'avis: 43\n",
      " - Prix réel: 67.00 €\n",
      " - Prix prédit: 73.21 €\n",
      " - Erreur: 9.3%\n",
      "\n",
      "🔍 Validation croisée du modèle avec 5 plis (sur l'entraînement)...\n",
      " - Scores de validation croisée (RMSE): 0.3083 (moyenne des scores MSE négatifs)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, StackingRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# 🔹 Chargement des données\n",
    "print(\"Chargement des données...\")\n",
    "data = pd.read_csv(\"listings.csv\")\n",
    "\n",
    "# Afficher les colonnes avec des valeurs manquantes et leur compte\n",
    "print(\"Colonnes avec valeurs manquantes:\")\n",
    "print(data.isnull().sum()[data.isnull().sum() > 0])\n",
    "\n",
    "# 🔹 Nettoyage des données\n",
    "# Suppression des lignes avec des valeurs manquantes pour les colonnes critiques\n",
    "data = data.dropna(subset=['latitude', 'longitude', 'price', 'number_of_reviews'])\n",
    "data = data[data['price'] > 0]\n",
    "\n",
    "# 🔹 Traitement explicite de toutes les valeurs manquantes\n",
    "# Remplir les valeurs manquantes pour reviews_per_month\n",
    "data['reviews_per_month'] = data['reviews_per_month'].fillna(0)\n",
    "\n",
    "# S'assurer que toutes les autres colonnes numériques n'ont pas de valeurs manquantes\n",
    "numeric_cols = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "for col in numeric_cols:\n",
    "    data[col] = data[col].fillna(data[col].median())\n",
    "\n",
    "# Remplacer les valeurs manquantes dans les colonnes catégorielles par 'unknown'\n",
    "categorical_cols = data.select_dtypes(include=['object']).columns\n",
    "for col in categorical_cols:\n",
    "    data[col] = data[col].fillna('unknown')\n",
    "\n",
    "# 🔹 Suppression de la colonne 'neighbourhood_group'\n",
    "data = data.drop(columns=['neighbourhood_group'])\n",
    "\n",
    "# 🔹 Création de nouvelles variables\n",
    "data['has_reviews'] = (data['number_of_reviews'] > 0).astype(int)\n",
    "data['high_availability'] = (data['availability_365'] > 180).astype(int)\n",
    "data['log_price'] = np.log1p(data['price'])\n",
    "data['reviews_density'] = data['number_of_reviews'] / (data['minimum_nights'] + 1)\n",
    "\n",
    "# 🔹 Features et target\n",
    "features = [\n",
    "    'latitude', 'longitude', 'minimum_nights', 'number_of_reviews',\n",
    "    'reviews_per_month', 'room_type',\n",
    "    'calculated_host_listings_count', 'has_reviews',\n",
    "    'high_availability', 'reviews_density'\n",
    "]\n",
    "target = 'log_price'\n",
    "\n",
    "# 🔹 Séparation des données en X et y\n",
    "X = data[features]\n",
    "y = data[target]\n",
    "\n",
    "# 🔹 Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "print(f\"Taille des données d'entraînement: {X_train.shape}\")\n",
    "print(f\"Taille des données de test: {X_test.shape}\")\n",
    "\n",
    "# 🔹 Colonnes\n",
    "numeric_features = [\n",
    "    'latitude', 'longitude', 'minimum_nights', 'number_of_reviews',\n",
    "    'reviews_per_month', 'calculated_host_listings_count', 'reviews_density'\n",
    "]\n",
    "categorical_features = ['room_type']\n",
    "\n",
    "# 🔹 Prétraitement avec SimpleImputer pour gérer les éventuelles valeurs manquantes\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='unknown')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numeric_transformer, numeric_features),\n",
    "    ('cat', categorical_transformer, categorical_features)\n",
    "])\n",
    "\n",
    "# 🔹 Création des modèles de base pour le Stacking\n",
    "base_models = [\n",
    "    ('ridge', Ridge(alpha=1.0, random_state=42)),\n",
    "    ('rf', RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42, n_jobs=-1)),\n",
    "    ('gbr', GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, random_state=42))\n",
    "]\n",
    "\n",
    "# 🔹 Méta-modèle avec paramètres explicites\n",
    "meta_model = Ridge(alpha=0.1, random_state=42)\n",
    "\n",
    "# 🔹 StackingRegressor avec validation croisée interne\n",
    "stacking = StackingRegressor(\n",
    "    estimators=base_models,\n",
    "    final_estimator=meta_model,\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# 🔹 Pipeline global avec prétraitement\n",
    "preproc_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('stacking', stacking)\n",
    "])\n",
    "\n",
    "# 🔹 GridSearchCV pour optimiser les paramètres du méta-modèle\n",
    "param_grid = {\n",
    "    'stacking__final_estimator__alpha': [0.1, 1.0, 10.0]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    preproc_pipeline,\n",
    "    param_grid,\n",
    "    cv=3,  # Réduit à 3 pour accélérer\n",
    "    scoring='neg_mean_squared_error',\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# 🔹 Validation croisée après l'entraînement\n",
    "try:\n",
    "    print(\"\\nDébut de l'entraînement du stacking (cela peut prendre un moment)...\")\n",
    "    grid.fit(X_train, y_train)\n",
    "    print(\"✅ Entraînement terminé avec succès!\")\n",
    "\n",
    "    # Meilleurs paramètres\n",
    "    print(f\"\\nMeilleurs paramètres trouvés: {grid.best_params_}\")\n",
    "\n",
    "    # 🔹 Prédiction et évaluation\n",
    "    y_pred = grid.predict(X_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    print(\"\\n📊 Évaluation du modèle (prix en échelle log) :\")\n",
    "    print(f\" - RMSE : {rmse:.4f}\")\n",
    "    print(f\" - MAE  : {mae:.4f}\")\n",
    "    print(f\" - R²   : {r2:.3f}\")\n",
    "\n",
    "    # 🔹 Réévaluation du modèle dans la vraie échelle du prix\n",
    "    print(\"\\n📊 Évaluation du modèle (prix en €) :\")\n",
    "    print(f\" - RMSE : {np.expm1(rmse):.2f} €\")\n",
    "    print(f\" - MAE  : {np.expm1(mae):.2f} €\")\n",
    "\n",
    "    # 🔹 Exemple de prédiction pour 3 annonces\n",
    "    sample_indices = np.random.choice(X_test.shape[0], 3, replace=False)\n",
    "    sample = X_test.iloc[sample_indices]\n",
    "    pred_log_price = grid.predict(sample)\n",
    "    \n",
    "    print(\"\\n🏠 Exemples d'annonces :\")\n",
    "    for i, idx in enumerate(sample_indices):\n",
    "        pred_price = np.expm1(pred_log_price[i])\n",
    "        real_price = np.expm1(y_test.iloc[idx])\n",
    "        error_pct = ((pred_price - real_price) / real_price) * 100\n",
    "\n",
    "        print(f\"\\nAnnonce {i+1}:\")\n",
    "        print(f\" - Type de logement: {sample.iloc[i]['room_type']}\")\n",
    "        print(f\" - Nombre d'avis: {sample.iloc[i]['number_of_reviews']}\")\n",
    "        print(f\" - Prix réel: {real_price:.2f} €\")\n",
    "        print(f\" - Prix prédit: {pred_price:.2f} €\")\n",
    "        print(f\" - Erreur: {error_pct:.1f}%\")\n",
    "\n",
    "    # 🔹 Validation croisée sur l'ensemble d'entraînement\n",
    "    print(\"\\n🔍 Validation croisée du modèle avec 5 plis (sur l'entraînement)...\")\n",
    "    cv_scores = cross_val_score(grid.best_estimator_, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "    print(f\" - Scores de validation croisée (RMSE): {-cv_scores.mean():.4f} (moyenne des scores MSE négatifs)\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Erreur lors de l'entraînement: {e}\")\n",
    "\n",
    "    # Analyse plus détaillée en cas d'erreur\n",
    "    print(\"\\nAnalyse des données pour déboguer:\")\n",
    "    print(f\"Shape de X_train: {X_train.shape}\")\n",
    "    print(f\"Nombre de NaN dans X_train: {X_train.isnull().sum().sum()}\")\n",
    "    if X_train.isnull().sum().sum() > 0:\n",
    "        print(\"Colonnes avec NaN dans X_train:\")\n",
    "        print(X_train.isnull().sum()[X_train.isnull().sum() > 0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f88f1f",
   "metadata": {},
   "source": [
    "Chargement et nettoyage des données\n",
    "\n",
    "\n",
    "Chargement des données : Le dataset listings.csv est chargé dans un DataFrame.\n",
    "\n",
    "Gestion des valeurs manquantes : Le code identifie et supprime les lignes où des colonnes critiques (latitude, longitude, price, number_of_reviews) sont manquantes. \n",
    "Les autres valeurs manquantes sont soit remplies par la médiane (pour les variables numériques)\n",
    "soit par une valeur constante (unknown pour les variables catégorielles).\n",
    "\n",
    "Filtrage des prix : Les lignes où le prix est inférieur ou égal à zéro sont supprimées.\n",
    "\n",
    "Création de nouvelles variables : Des colonnes supplémentaires sont créées\n",
    "comme has_reviews (indiquant si l'annonce a des avis), \n",
    "high_availability (indiquant si la disponibilité est supérieure à 180 jours), \n",
    "log_price (le prix transformé logarithmiquement)\n",
    "reviews_density (la densité des avis).\n",
    "\n",
    "2. Préparation des données pour l'entraînement\n",
    "\n",
    "\n",
    "\n",
    "Sélection des variables explicatives (features) et de la cible (log_price).\n",
    "\n",
    "Séparation en ensembles d'entraînement et de test : L'ensemble de données est divisé en 75% pour l'entraînement et 25% pour le test.\n",
    "\n",
    "Définition des colonnes numériques et catégorielles pour un prétraitement ultérieur.\n",
    "\n",
    "3. Prétraitement des données\n",
    "\n",
    "\n",
    "\n",
    "Transformation des variables numériques : Les valeurs manquantes sont imputées avec la médiane et les données sont normalisées avec StandardScaler.\n",
    "\n",
    "Transformation des variables catégorielles : Les valeurs manquantes sont imputées avec la valeur unknown \n",
    "les variables catégorielles sont transformées en variables binaires avec OneHotEncoder.\n",
    "\n",
    "4. Modélisation par Stacking\n",
    "\n",
    "\n",
    "\n",
    "Création de modèles de base pour le stacking : Trois modèles sont utilisés en base :\n",
    "\n",
    "Ridge : Régression linéaire avec régularisation L2.\n",
    "\n",
    "RandomForestRegressor : Forêt d'arbres de régression.\n",
    "\n",
    "GradientBoostingRegressor : Gradient boosting pour la régression.\n",
    "\n",
    "Méthode de Stacking : Les résultats de ces trois modèles de base sont combinés dans un modèle de stacking avec un modèle final (meta_model), ici un modèle Ridge.\n",
    "\n",
    "5. Optimisation des hyperparamètres\n",
    "\n",
    "\n",
    "\n",
    "GridSearchCV : Une recherche de grille est effectuée pour optimiser l'hyperparamètre alpha du modèle Ridge dans le stacking. La grille cherche les meilleures valeurs de alpha pour le méta-modèle.\n",
    "\n",
    "6. Évaluation et résultats\n",
    "\n",
    "\n",
    "\n",
    "Entraînement du modèle : Le modèle de stacking est entraîné avec les données d'entraînement.\n",
    "\n",
    "Évaluation : Les performances du modèle sont évaluées à l'aide de différentes métriques :\n",
    "\n",
    "RMSE (Root Mean Squared Error) et MAE (Mean Absolute Error) sur l'échelle log du prix.\n",
    "\n",
    "R² (coefficient de détermination).\n",
    "\n",
    "Réévaluation des prix réels en revenant à l’échelle d’origine (en €) avec la fonction np.expm1() (inverse de np.log1p()).\n",
    "\n",
    "Prédictions sur des exemples d'annonces : Le modèle prédit les prix pour quelques annonces de test et compare ces prédictions avec les valeurs réelles\n",
    "\n",
    "calculant l'erreur en pourcentage.\n",
    "\n",
    "7. Validation croisée\n",
    "\n",
    "\n",
    "\n",
    "Validation croisée : Le modèle est évalué avec une validation croisée à 5 plis pour donner une estimation de la robustesse du modèle.\n",
    "\n",
    "8. Gestion des erreurs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Si une erreur survient lors de l'entraînement (par exemple, des problèmes de données), des messages d'erreur sont affichés\n",
    "et le code effectue une analyse pour comprendre les problèmes (par exemple, la présence de valeurs manquantes).\n",
    "\n",
    "\n",
    "Le code effectue un prétraitement complet des données\n",
    "utilise un modèle de stacking pour combiner plusieurs régressions (Ridge, Random Forest, Gradient Boosting) \n",
    "optimise les paramètres du modèle via GridSearchCV. \n",
    "Ensuite, il évalue les performances du modèle en termes de RMSE, MAE, et R², à la fois sur l’échelle logarithmique du prix et sur l’échelle d’origine. \n",
    "Il permet également de visualiser l’erreur de prédiction pour quelques annonces spécifiques et d’effectuer une validation croisée pour mesurer la stabilité du modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9224062",
   "metadata": {},
   "source": [
    "Interprétation des Résultats\n",
    "\n",
    "\n",
    "\n",
    "1. Meilleurs paramètres du modèle\n",
    "stacking__final_estimator__alpha = 0.1 : Le meilleur paramètre pour le méta-modèle Ridge (utilisé dans le stacking) est alpha = 0.1. Cela signifie que la régularisation L2 a été ajustée pour un niveau de pénalisation relativement faible, ce qui peut avoir permis de mieux adapter le modèle aux données sans trop le contraindre.\n",
    "\n",
    "\n",
    "\n",
    "2. Évaluation du modèle (prix en échelle log) :\n",
    "RMSE : 0.5114 : Le Root Mean Squared Error (erreur quadratique moyenne) en échelle logarithmique est de 0.5114. Cette valeur mesure la différence moyenne entre les valeurs réelles et prédites, mais sur l'échelle log du prix. Plus cette valeur est faible, plus les prédictions sont précises. Un RMSE de 0.5114 indique une performance raisonnable.\n",
    "\n",
    "\n",
    "\n",
    "MAE : 0.3716 : Le Mean Absolute Error (erreur absolue moyenne) en échelle logarithmique est de 0.3716, ce qui signifie que l'erreur moyenne (en log) par prédiction est de 0.3716. Cela montre également une erreur modérée entre les prix réels et les prédictions.\n",
    "\n",
    "R² : 0.505 : Le coefficient de détermination (R²) est de 0.505, ce qui signifie que le modèle explique environ 50.5% de la variance des prix en échelle log. Un R² de 0.505 montre un modèle avec une performance relativement modérée. Il reste un certain potentiel d'amélioration.\n",
    "\n",
    "\n",
    "\n",
    "3. Évaluation du modèle (prix en €) :\n",
    "RMSE : 0.67 € : Une fois les prédictions converties sur l’échelle réelle du prix, l'erreur quadratique moyenne est de 0.67 €. Cela donne une idée de l'erreur réelle sur les prix en €.\n",
    "\n",
    "MAE : 0.45 € : L'erreur absolue moyenne en termes de prix réels est de 0.45 €, ce qui donne une idée de la précision globale du modèle dans la prédiction des prix.\n",
    "\n",
    "\n",
    "\n",
    "4. Exemples d'annonces\n",
    "Le modèle a prédit des prix pour quelques annonces de test, avec des erreurs d'environ 9.3%. Cela montre que les prédictions sont assez proches des valeurs réelles, mais il reste des erreurs notables. Une erreur de 9.3% peut être acceptable dans un cadre de prédiction de prix, mais il y a toujours des opportunités pour améliorer la précision, notamment en optimisant davantage les paramètres ou en utilisant des modèles alternatifs.\n",
    "\n",
    "\n",
    "\n",
    "5. Validation croisée\n",
    "Scores de validation croisée (RMSE) : 0.3083 : La validation croisée montre une erreur moyenne de 0.3083 (sur 5 plis), ce qui est une bonne mesure de la stabilité et de la généralisation du modèle. Un score plus faible en validation croisée suggère que le modèle ne surajuste pas trop aux données d'entraînement et qu'il peut bien généraliser aux nouvelles données.\n",
    "\n",
    "\n",
    "\n",
    "Conclusion\n",
    "\n",
    "\n",
    "Performance globale : Le modèle de stacking montre une performance raisonnable avec un R² de 0.505, ce qui signifie qu'il explique environ 50% de la variance des prix. Cependant, le modèle peut être amélioré pour mieux expliquer cette variance et réduire les erreurs.\n",
    "\n",
    "Marge d'amélioration : Bien que l'erreur soit acceptable pour certaines applications (9.3% d'erreur sur des exemples d'annonces), des améliorations peuvent être apportées en ajustant les hyperparamètres, en utilisant d'autres modèles (par exemple, des modèles plus complexes ou non-linéaires), ou en ajoutant de nouvelles caractéristiques aux données.\n",
    "\n",
    "Validation croisée solide : La validation croisée suggère que le modèle est robuste et qu'il généralise bien, ce qui est un bon signe pour sa stabilité."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995cb1be",
   "metadata": {},
   "source": [
    "Limites du Modèle\n",
    "\n",
    "\n",
    "Précision modérée (R² de 0.505) :\n",
    "\n",
    "Le modèle explique seulement 50.5% de la variance des prix, ce qui indique que plus de 40% des variations de prix ne sont pas capturées par le modèle. Cela montre une marge d'amélioration importante pour mieux comprendre les facteurs influençant le prix.\n",
    "\n",
    "Erreur relativement élevée sur les prix réels (RMSE de 0.67 €) :\n",
    "\n",
    "L'erreur quadratique moyenne de 0.67 € sur les prix réels peut être jugée acceptable, mais elle montre que le modèle a encore du mal à prédire précisément certains prix. Cela peut être problématique dans des contextes où une grande précision est requise (par exemple, la recommandation de prix dans une plateforme de vente).\n",
    "\n",
    "Caractéristiques limitées :\n",
    "\n",
    "\n",
    "\n",
    "Les caractéristiques utilisées (latitude, longitude, type de chambre, nombre de nuits minimales, etc.) sont relativement simples et peuvent ne pas capturer tous les facteurs importants influençant le prix d'une annonce. Par exemple, des informations sur les images de l'annonce, les équipements offerts, la proximité de lieux populaires ou des informations sur l'hôte peuvent être pertinentes mais ne sont pas prises en compte ici.\n",
    "\n",
    "Interaction entre les caractéristiques :\n",
    "\n",
    "Le modèle actuel ne capture peut-être pas assez bien les interactions complexes entre les différentes caractéristiques. Par exemple, la combinaison du type de chambre avec la disponibilité pourrait influencer davantage le prix, mais ces interactions ne sont pas explicitement modélisées.\n",
    "\n",
    "Surajustement possible dans certains modèles de base :\n",
    "\n",
    "Bien que la validation croisée suggère que le modèle généralise bien, certains des modèles de base (comme le RandomForestRegressor) peuvent toujours être sensibles au surajustement si les hyperparamètres ne sont pas bien réglés.\n",
    "\n",
    "Suggestions d'Amélioration\n",
    "\n",
    "\n",
    "Ajout de nouvelles caractéristiques :\n",
    "\n",
    "Caractéristiques liées aux images : Ajouter des informations sur les images des annonces (par exemple, la qualité, le nombre d'images) pourrait améliorer la précision des prédictions.\n",
    "\n",
    "Caractéristiques géographiques supplémentaires : Par exemple, la proximité de points d'intérêt, comme des attractions touristiques ou des centres de transport, pourrait influencer le prix.\n",
    "\n",
    "Caractéristiques sur l'hôte : Le nombre d'années d'activité de l'hôte, la réputation de l'hôte (note moyenne, nombre d'avis) pourrait avoir un impact sur le prix.\n",
    "\n",
    "Exploration de modèles plus avancés :\n",
    "\n",
    "Modèles non-linéaires complexes : Des modèles comme les réseaux de neurones (NN), XGBoost, ou CatBoost pourraient capturer des relations plus complexes entre les caractéristiques. Ces modèles sont souvent très performants sur des données comme celles-ci.\n",
    "\n",
    "Modèles de type Gradient Boosting comme XGBoost, LightGBM, ou CatBoost : Ces modèles sont bien adaptés aux données tabulaires avec des interactions complexes et des relations non-linéaires.\n",
    "\n",
    "Optimisation de l'architecture du Stacking :\n",
    "\n",
    "Ajout d'autres modèles de base : Vous pourriez intégrer des modèles comme SVM, KNN, ou des réseaux de neurones comme modèles de base dans le stacking pour en améliorer les performances.\n",
    "\n",
    "Réduction du nombre de modèles de base : Parfois, simplifier le stacking en réduisant le nombre de modèles de base peut également améliorer la performance, si ces modèles ne sont pas réellement complémentaires.\n",
    "\n",
    "\n",
    "\n",
    "Optimisation des hyperparamètres :\n",
    "\n",
    "Hyperparamètres des modèles de base : Effectuer une recherche plus exhaustive des hyperparamètres des modèles de base comme le RandomForestRegressor et le GradientBoostingRegressor peut améliorer les performances du stacking.\n",
    "\n",
    "Utilisation de techniques comme le Bayesian Optimization pour rechercher de manière plus efficace les hyperparamètres du stacking et des modèles de base.\n",
    "\n",
    "\n",
    "\n",
    "Feature Engineering :\n",
    "\n",
    "Interactions entre les caractéristiques : Vous pourriez essayer de créer de nouvelles caractéristiques représentant des interactions entre les caractéristiques existantes. Par exemple, combiner les informations de latitude/longitude pour créer des clusters géographiques et voir comment ces clusters affectent le prix.\n",
    "\n",
    "Transformation des variables : Certaines variables (comme le nombre de nuits minimales ou le nombre d'avis) peuvent bénéficier de transformations non linéaires ou d'encodages spécifiques (logarithmiques, par exemple).\n",
    "\n",
    "Amélioration de la gestion des valeurs manquantes :\n",
    "\n",
    "\n",
    "\n",
    "Bien que vous ayez déjà bien géré les valeurs manquantes, il peut être utile d'explorer des méthodes de prédiction des valeurs manquantes plus complexes, comme des modèles de prédiction pour les variables manquantes (par exemple, en utilisant un modèle de régression pour prédire les valeurs manquantes).\n",
    "\n",
    "\n",
    "Utilisation de l'architecture \"Ensemble\" :\n",
    "\n",
    "Envisagez des méthodes Ensemble plus avancées, comme Stacking combinée avec Boosting ou Bagging, pour obtenir de meilleurs résultats en combinant plusieurs types de modèles.\n",
    "\n",
    "\n",
    "\n",
    "Suivi de la stabilité et de la robustesse des prédictions :\n",
    "\n",
    "Analyser les erreurs par région géographique ou par type de logement pourrait vous donner des indications sur les cas où le modèle échoue. Par exemple, peut-être que le modèle sous-estime les prix dans certaines zones ou types de logement, ce qui pourrait guider des améliorations supplémentaires dans les caractéristiques du modèle."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ML 2025)",
   "language": "python",
   "name": "ml-project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
